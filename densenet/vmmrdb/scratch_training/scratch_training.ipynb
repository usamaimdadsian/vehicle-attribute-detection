{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from xml.etree import ElementTree as ET\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_DATASET = \"/home/kk/Desktop/usama/datasets/VMMRdb\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = None\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,X,y,all_classes, root_dir, transform=None ) -> None:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.root_dir = root_dir\n",
    "        assert len(self.X) == len(self.y)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.label_map = {label: idx for idx, label in enumerate(set(all_classes))}\n",
    "        for i,label in enumerate(self.label_map.keys()):\n",
    "          self.label_map[label] = i\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        img_path = os.path.join(self.root_dir, label, img_name)\n",
    "\n",
    "        label_arr = label.split('_')\n",
    "        label = \"_\".join(label_arr[:-1])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        label = torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, test_loader):\n",
    "  with torch.no_grad():\n",
    "      total_correct = 0\n",
    "      total_samples = 0\n",
    "      for images, labels in test_loader:\n",
    "          images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total_correct += (predicted == labels).sum().item()\n",
    "          total_samples += labels.size(0)\n",
    "\n",
    "      accuracy = total_correct / total_samples\n",
    "      print(f'Test Accuracy On best Model: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(epochs, model, criterion, optimizer, train_loader, valid_loader, test_loader):\n",
    "  best_model = None\n",
    "  best_acc = 0\n",
    "\n",
    "  # Training loop\n",
    "  for epoch in range(epochs):\n",
    "      model.train()\n",
    "      total_train_correct = 0\n",
    "      total_train_samples = 0\n",
    "      tqdm_train_loader = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}')\n",
    "      for images, labels in tqdm_train_loader:\n",
    "          images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total_train_correct += (predicted == labels).sum().item()\n",
    "          total_train_samples += labels.size(0)\n",
    "      train_accuracy = total_train_correct / total_train_samples\n",
    "\n",
    "      # Validation loop\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "          total_correct = 0\n",
    "          total_samples = 0\n",
    "          for images, labels in valid_loader:\n",
    "              images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "              outputs = model(images)\n",
    "              _, predicted = torch.max(outputs, 1)\n",
    "              total_correct += (predicted == labels).sum().item()\n",
    "              total_samples += labels.size(0)\n",
    "\n",
    "          accuracy = total_correct / total_samples\n",
    "          print(f'Epoch [{epoch+1}/{epochs}], Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "          if (accuracy > best_acc):\n",
    "            print(\"New Best Model with Accuracy: \", accuracy)\n",
    "            best_acc = accuracy\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model,\"scratch_training_E\"+str(epoch)+\"pt\")\n",
    "\n",
    "  print(\"Training finished.\")\n",
    "\n",
    "  # Testing the model\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      total_correct = 0\n",
    "      total_samples = 0\n",
    "      for images, labels in test_loader:\n",
    "          images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "          outputs = best_model(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total_correct += (predicted == labels).sum().item()\n",
    "          total_samples += labels.size(0)\n",
    "\n",
    "      accuracy = total_correct / total_samples\n",
    "      print(f'Test Accuracy On best Model: {accuracy:.4f}')\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Images: 285086 TOTAL CLASSES:  1175\n"
     ]
    }
   ],
   "source": [
    "classes_list = os.listdir(FOLDER_DATASET)\n",
    "dataset_list = []\n",
    "\n",
    "for _class in classes_list:\n",
    "  images = os.listdir(os.path.join(FOLDER_DATASET,_class))\n",
    "  for image in images:\n",
    "    class_l =  _class.split(\"_\")\n",
    "    dataset_list.append((image,_class,\"_\".join(class_l[:-1])))\n",
    "dataset_list = np.array(dataset_list)\n",
    "NUM_CLASSES = len(np.unique(dataset_list[:,2]))\n",
    "\n",
    "print(\"Dataset Images:\",len(dataset_list), \"TOTAL CLASSES: \", NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset_list[:,0],dataset_list[:,1], test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(X_train,y_train,dataset_list[:,2],FOLDER_DATASET, transform)\n",
    "valid_dataset = CustomDataset(X_val, y_val,dataset_list[:,2], FOLDER_DATASET, transform)\n",
    "test_dataset = CustomDataset(X_test,y_test,dataset_list[:,2], FOLDER_DATASET, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 5346/5346 [1:06:57<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Training Accuracy: 0.0557, Validation Accuracy: 0.1043\n",
      "New Best Model with Accuracy:  0.10431976428082852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 5346/5346 [1:14:33<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Training Accuracy: 0.2111, Validation Accuracy: 0.3171\n",
      "New Best Model with Accuracy:  0.3170633319887051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 5346/5346 [1:14:54<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Training Accuracy: 0.4119, Validation Accuracy: 0.4794\n",
      "New Best Model with Accuracy:  0.4793658031815073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 5346/5346 [1:13:48<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Training Accuracy: 0.5459, Validation Accuracy: 0.5752\n",
      "New Best Model with Accuracy:  0.5751793324797867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 5346/5346 [1:13:49<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Training Accuracy: 0.6355, Validation Accuracy: 0.6212\n",
      "New Best Model with Accuracy:  0.6212006945297016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15:  63%|██████▎   | 3360/5346 [45:43<30:14,  1.09it/s]  "
     ]
    }
   ],
   "source": [
    "model = models.densenet121(weights=None, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "best_model = train(EPOCHS,model,criterion,optimizer,train_loader,valid_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,\"vmmrdb_pretraining.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_usama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
